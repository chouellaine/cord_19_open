{"cluster": 9, "subcluster": 2, "abstract_summ": "We validate our method using in-house customer survey data and compare it to other state-of-the-art learning methods.Using real-world data, we show that our approach outperforms other state-of-the-art methods with a gain of 4x over the standard case and a 12% improvement over the second-best method.For complex and high-dimensional data, neural networks can learn feature embeddings to which traditional ssl methods can then be applied in what we call hybrid methods.There exist different methods for solving inverse problems, including gradient based methods, statistics based methods, and Deep Learning (DL) methods.However, most existing methods neglect the complex correlation among data samples, which is important for capturing normal patterns from which the abnormal ones deviate.", "title_summ": "NetworkAccelerating Hyperparameter Optimization of Deep Neural Network via Progressive Multi-Fidelity EvaluationCross-data Automatic Feature Engineering via Meta-learning and Reinforcement LearningDeep Multimodal Clustering with Cross ReconstructionDeep Multivariate Time Series Embedding Clustering via Attentive-Gated AutoencoderSelf-supervised Learning for Semi-supervised Time Series ClassificationL0-norm Constrained Autoencoders for Unsupervised Outlier DetectionAdversarial Autoencoder and Multi-Task Semi-Supervised Learning for Multi-stage ProcessOptimal Topology Search for Fast Model Averaging in Decentralized Parallel SGDMsFcNET: Multi-scale Feature-Crossing Attention Network for Multi-field Sparse DataMulti-view Deep Gaussian Process with a Pre-training Acceleration TechniqueCorrelation-Aware Deep Generative Model for Unsupervised Anomaly DetectionTask-Projected Hyperdimensional Computing for Multi-task LearningRegularized Evolution for Macro Neural Architecture SearchEvolving Long Short-Term Memory NetworksMissing Features ReconstructionUsing a Wasserstein Generative Adversarial Imputation NetworkDesign of Loss Functions for Solving Inverse Problems Using Deep LearningDeep Low-Density Separation for Semi-supervised ClassificationMulti-objective Combinatorial Generative Adversarial Optimization and Its Application in CrowdsensingMulti-Objective Neural Architecture Search Based on Diverse Structures and Adaptive RecommendationNovelty Detection via Robust Variational AutoencodingTransfer Learning or Self-supervised Learning?Curiosity-Driven Variational Autoencoder for Deep QParadigmsSample-Efficient Optimization in the Latent Space of Deep Generative Models via Weighted RetrainingA Tale of Two Pretraining", "title_abstract_phrases": "We validate our method using in-house customer survey data and compare it to other state-of-the-art learning methods.There exist different methods for solving inverse problems, including gradient based methods, statistics based methods, and Deep Learning (DL) methods.Using real-world data, we show that our approach outperforms other state-of-the-art methods with a gain of 4x over the standard case and a 12% improvement over the second-best method.For complex and high-dimensional data, neural networks can learn feature embeddings to which traditional ssl methods can then be applied in what we call hybrid methods.However, most existing methods neglect the complex correlation among data samples, which is important for capturing normal patterns from which the abnormal ones deviate."}