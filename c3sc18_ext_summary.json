{"cluster": 3, "subcluster": 18, "abstract_summ": "To this end, we propose Document-level Attention for Keyphrase Extraction (DAKE), which comprises Bidirectional Long Short-Term Memory networks that capture hidden semantics in text, a document-level attention mechanism to incorporate document level contextual information, gating mechanisms which help to determine the influence of additional contextual information on the fusion with local contextual information, and Conditional Random Fields which capture output label dependencies.In this paper, we propose a new model that applies the three-way decision theory to graph-based keyphrase extraction model.Previous approaches for keyphrase extraction model it as a sequence labelling task and use local contextual information to understand the semantics of the input text but they fail when the local context is ambiguous or unclear.The mainstream methods are supervised learning methods and graph-based methods.Experimental results on a publicly available dataset show that our over-sampling technique, coupled with the multi-task framework outperforms state-of-the-art open domain suggestion mining models in terms of the F-1 measure and AUC.Since its introduction some twenty years ago, named entity (NE) processing has become an essential component of virtually any text mining application and has undergone major changes.", "title_summ": "Document-Level Attention for Keyphrase ExtractionMulti-level Memory Network with CRFs for Keyphrase ExtractionFeature Extraction with TF-IDF and Game-Theoretic Shadowed SetsSciNER: Extracting Named Entities from Scientific LiteratureDetecting the Most Insightful Parts of Documents Using a Regularized Attention-Based ModelA Graph-Based Keyphrase Extraction Model with Three-Way DecisionA Multi-task Approach to Open Domain Suggestion Mining Using Language Model for Text Over-SamplingIntroducing the CLEF 2020 HIPE Shared Task:Named Entity Recognition and Linking on Historical NewspapersDAKE:", "title_abstract_phrases": "In this paper, we propose a new model that applies the three-way decision theory to graph-based keyphrase extraction model.To this end, we propose Document-level Attention for Keyphrase Extraction (DAKE), which comprises Bidirectional Long Short-Term Memory networks that capture hidden semantics in text, a document-level attention mechanism to incorporate document level contextual information, gating mechanisms which help to determine the influence of additional contextual information on the fusion with local contextual information, and Conditional Random Fields which capture output label dependencies.Experimental results on a publicly available dataset show that our over-sampling technique, coupled with the multi-task framework outperforms state-of-the-art open domain suggestion mining models in terms of the F-1 measure and AUC.Introducing the CLEF 2020 HIPE Shared Task:In recent years, the development of the graph-based method has made great progress and its performance of extraction is getting closer and closer to the supervised method, so the graph-based method of keyphrase extraction has got a wide concern from researchers.This work uses a regularized attention-based method to detect the most influential part(s) of any given document or text."}